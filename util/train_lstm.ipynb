{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normal': 0, 'shoplifting': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "nama_folder = r\"FINAL_clean binary\\npy\"\n",
    "# for subdir, dirs, files in os.walk(nama_folder):\n",
    "#     for file in files:\n",
    "#         res = numpy.load(os.path.join(subdir, file))\n",
    "#         print(os.path.join(subdir, file))\n",
    "#         for i in res:\n",
    "#             print(i)\n",
    "#         print(\"\\n\\n\")\n",
    "\n",
    "# res = np.load(\"kamar_webcamlogi/context_data/normal_2.avi.npy\")\n",
    "# print(res.shape)\n",
    "# # print(os.path.join(\"context_cek algoritma/context_data_shoplift/0.avi.npy\"))\n",
    "# for i in res:\n",
    "#     print(i)\n",
    "\n",
    "\n",
    "\n",
    "# Jumlah klip utk per class\n",
    "no_sequences = 111\n",
    "# Panjang total sliding window utk masuk model sequence classification\n",
    "sequence_length = 60\n",
    "\n",
    "# Actions that we try to detect\n",
    "actions = np.array(['normal', 'shoplifting'])\n",
    "\n",
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "\n",
    "print(label_map)\n",
    "\n",
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for num in range(1,no_sequences+1):\n",
    "        window = np.load(os.path.join(nama_folder, action, \" ({}).npy\".format(num)))\n",
    "        window = window.astype('float64') \n",
    "\n",
    "        window_holder = []\n",
    "        for idx_frame, per_frame in enumerate(window):\n",
    "            if(idx_frame+1)%2==0:\n",
    "                per_frame_holder = []\n",
    "                for i in range(len(per_frame)):\n",
    "                    if(i in [0,2,4,6,8,10,12,14]):\n",
    "                        if(per_frame[i] == 0):\n",
    "                            per_frame_holder.append(float(-1))\n",
    "                        else:\n",
    "                            per_frame_holder.append(float((per_frame[i]/640)-0.5))\n",
    "                    else:\n",
    "                        if(per_frame[i] == 0):\n",
    "                            per_frame_holder.append(float(-1))\n",
    "                        else:\n",
    "                            per_frame_holder.append((per_frame[i]/480)-0.5)\n",
    "                window_holder.append(per_frame_holder)\n",
    "\n",
    "        # for per_frame in window:\n",
    "        #     for i in range(len(per_frame)):\n",
    "        #         if(i in [0,2,4,6,8,10,12,14]):\n",
    "        #             if(per_frame[i] == 0):\n",
    "        #                 per_frame[i] = -1\n",
    "        #             else:\n",
    "        #                 per_frame[i] = float((per_frame[i]/640)-0.5)\n",
    "        #         else:\n",
    "        #             if(per_frame[i] == 0):\n",
    "        #                 per_frame[i] = -1\n",
    "        #             else:\n",
    "        #                 per_frame[i] = float((per_frame[i]/480)-0.5)\n",
    "            # print(per_frame)\n",
    "        sequences.append(window_holder)\n",
    "        labels.append(label_map[action])\n",
    "\n",
    "# print(\"\\n\\nSEQUENCE\")\n",
    "# print(np.array(sequences).shape)\n",
    "# print(sequences)\n",
    "\n",
    "# print(\"\\n\\nLABELS\")\n",
    "# print(np.array(labels).shape)\n",
    "# print(labels)\n",
    "\n",
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222, 25, 18)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(8, return_sequences=True, activation='relu', input_shape=(25,18)))\n",
    "model.add(LSTM(4, return_sequences=False, activation='relu'))\n",
    "# model.add(LSTM(4, return_sequences=False, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))\n",
    "\n",
    "# num_classes = 2\n",
    "\n",
    "# def make_model(input_shape):\n",
    "#     input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "#     conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "#     conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "#     conv1 = keras.layers.ReLU()(conv1)\n",
    "\n",
    "#     conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "#     conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "#     conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "#     conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "#     conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "#     conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "#     gap = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "#     output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(gap)\n",
    "\n",
    "#     return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "# model = make_model(input_shape=X_train.shape[1:])\n",
    "\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 2s 81ms/step - loss: 0.7839 - categorical_accuracy: 0.3842 - val_loss: 0.6741 - val_categorical_accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7191 - categorical_accuracy: 0.4011 - val_loss: 0.6359 - val_categorical_accuracy: 0.5111\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6786 - categorical_accuracy: 0.4237 - val_loss: 0.6069 - val_categorical_accuracy: 0.4889\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6402 - categorical_accuracy: 0.5650 - val_loss: 0.5852 - val_categorical_accuracy: 0.6444\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6117 - categorical_accuracy: 0.7119 - val_loss: 0.5659 - val_categorical_accuracy: 0.6889\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5830 - categorical_accuracy: 0.7910 - val_loss: 0.5496 - val_categorical_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.5510 - categorical_accuracy: 0.7966 - val_loss: 0.5408 - val_categorical_accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5319 - categorical_accuracy: 0.8192 - val_loss: 0.5343 - val_categorical_accuracy: 0.7111\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5121 - categorical_accuracy: 0.8192 - val_loss: 0.5422 - val_categorical_accuracy: 0.7556\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.4821 - categorical_accuracy: 0.8362 - val_loss: 0.4947 - val_categorical_accuracy: 0.7556\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4618 - categorical_accuracy: 0.8475 - val_loss: 0.4778 - val_categorical_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.4375 - categorical_accuracy: 0.8531 - val_loss: 0.4583 - val_categorical_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4142 - categorical_accuracy: 0.8531 - val_loss: 0.4232 - val_categorical_accuracy: 0.8222\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.3881 - categorical_accuracy: 0.8588 - val_loss: 0.3949 - val_categorical_accuracy: 0.8444\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.3494 - categorical_accuracy: 0.8644 - val_loss: 0.4123 - val_categorical_accuracy: 0.8444\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3282 - categorical_accuracy: 0.8644 - val_loss: 0.4203 - val_categorical_accuracy: 0.8444\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.3040 - categorical_accuracy: 0.8644 - val_loss: 0.3841 - val_categorical_accuracy: 0.8222\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2828 - categorical_accuracy: 0.8757 - val_loss: 0.4347 - val_categorical_accuracy: 0.8444\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2541 - categorical_accuracy: 0.8644 - val_loss: 0.3313 - val_categorical_accuracy: 0.8889\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.2640 - categorical_accuracy: 0.8927 - val_loss: 0.3535 - val_categorical_accuracy: 0.8667\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2509 - categorical_accuracy: 0.8814 - val_loss: 0.3173 - val_categorical_accuracy: 0.9111\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.2398 - categorical_accuracy: 0.9096 - val_loss: 0.3461 - val_categorical_accuracy: 0.8889\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2257 - categorical_accuracy: 0.9040 - val_loss: 0.3109 - val_categorical_accuracy: 0.9111\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.1998 - categorical_accuracy: 0.9266 - val_loss: 0.4005 - val_categorical_accuracy: 0.8889\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2316 - categorical_accuracy: 0.9096 - val_loss: 0.3347 - val_categorical_accuracy: 0.9111\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1935 - categorical_accuracy: 0.9153 - val_loss: 0.3164 - val_categorical_accuracy: 0.8889\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2094 - categorical_accuracy: 0.9266 - val_loss: 0.3284 - val_categorical_accuracy: 0.8889\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1724 - categorical_accuracy: 0.9266 - val_loss: 0.3195 - val_categorical_accuracy: 0.8667\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1929 - categorical_accuracy: 0.9266 - val_loss: 0.3055 - val_categorical_accuracy: 0.9111\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1647 - categorical_accuracy: 0.9435 - val_loss: 0.2883 - val_categorical_accuracy: 0.9111\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1507 - categorical_accuracy: 0.9379 - val_loss: 0.3865 - val_categorical_accuracy: 0.8889\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1446 - categorical_accuracy: 0.9435 - val_loss: 0.3523 - val_categorical_accuracy: 0.8889\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1478 - categorical_accuracy: 0.9379 - val_loss: 0.3356 - val_categorical_accuracy: 0.9111\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1285 - categorical_accuracy: 0.9435 - val_loss: 0.2609 - val_categorical_accuracy: 0.8889\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2092 - categorical_accuracy: 0.9266 - val_loss: 0.4866 - val_categorical_accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.4847 - categorical_accuracy: 0.9040 - val_loss: 0.4921 - val_categorical_accuracy: 0.8667\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2342 - categorical_accuracy: 0.8870 - val_loss: 0.4183 - val_categorical_accuracy: 0.8222\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2422 - categorical_accuracy: 0.8757 - val_loss: 0.3679 - val_categorical_accuracy: 0.8444\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2346 - categorical_accuracy: 0.9040 - val_loss: 0.2928 - val_categorical_accuracy: 0.8444\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2071 - categorical_accuracy: 0.9209 - val_loss: 0.2830 - val_categorical_accuracy: 0.8889\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.1938 - categorical_accuracy: 0.9266 - val_loss: 0.3274 - val_categorical_accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1710 - categorical_accuracy: 0.9322 - val_loss: 0.4354 - val_categorical_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1621 - categorical_accuracy: 0.9435 - val_loss: 0.4760 - val_categorical_accuracy: 0.8889\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1738 - categorical_accuracy: 0.9266 - val_loss: 0.3164 - val_categorical_accuracy: 0.8889\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1353 - categorical_accuracy: 0.9718 - val_loss: 0.2848 - val_categorical_accuracy: 0.9111\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1208 - categorical_accuracy: 0.9548 - val_loss: 0.2735 - val_categorical_accuracy: 0.8889\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1065 - categorical_accuracy: 0.9718 - val_loss: 0.2678 - val_categorical_accuracy: 0.9333\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0902 - categorical_accuracy: 0.9774 - val_loss: 0.2913 - val_categorical_accuracy: 0.9111\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0837 - categorical_accuracy: 0.9831 - val_loss: 0.2896 - val_categorical_accuracy: 0.8444\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0828 - categorical_accuracy: 0.9774 - val_loss: 0.3511 - val_categorical_accuracy: 0.9111\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0923 - categorical_accuracy: 0.9774 - val_loss: 0.2862 - val_categorical_accuracy: 0.8444\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1079 - categorical_accuracy: 0.9492 - val_loss: 0.2801 - val_categorical_accuracy: 0.9111\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0733 - categorical_accuracy: 0.9774 - val_loss: 0.3212 - val_categorical_accuracy: 0.8889\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0807 - categorical_accuracy: 0.9718 - val_loss: 0.3305 - val_categorical_accuracy: 0.9111\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0731 - categorical_accuracy: 0.9718 - val_loss: 0.2930 - val_categorical_accuracy: 0.8889\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0670 - categorical_accuracy: 0.9774 - val_loss: 0.3720 - val_categorical_accuracy: 0.8889\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0611 - categorical_accuracy: 0.9774 - val_loss: 0.3009 - val_categorical_accuracy: 0.8444\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0425 - categorical_accuracy: 0.9831 - val_loss: 0.3701 - val_categorical_accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0450 - categorical_accuracy: 0.9774 - val_loss: 0.3889 - val_categorical_accuracy: 0.8444\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0408 - categorical_accuracy: 0.9831 - val_loss: 0.3513 - val_categorical_accuracy: 0.8889\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0601 - categorical_accuracy: 0.9661 - val_loss: 1.3170 - val_categorical_accuracy: 0.8000\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1698 - categorical_accuracy: 0.9435 - val_loss: 0.4227 - val_categorical_accuracy: 0.8667\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2992 - categorical_accuracy: 0.9322 - val_loss: 0.5306 - val_categorical_accuracy: 0.8667\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2633 - categorical_accuracy: 0.9435 - val_loss: 0.4726 - val_categorical_accuracy: 0.8444\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1934 - categorical_accuracy: 0.9153 - val_loss: 0.4660 - val_categorical_accuracy: 0.8667\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1791 - categorical_accuracy: 0.9266 - val_loss: 0.4108 - val_categorical_accuracy: 0.8667\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1612 - categorical_accuracy: 0.9492 - val_loss: 0.3536 - val_categorical_accuracy: 0.8889\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.1400 - categorical_accuracy: 0.9605 - val_loss: 0.3298 - val_categorical_accuracy: 0.9111\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1184 - categorical_accuracy: 0.9661 - val_loss: 0.3575 - val_categorical_accuracy: 0.9111\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1057 - categorical_accuracy: 0.9661 - val_loss: 0.3488 - val_categorical_accuracy: 0.9111\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0837 - categorical_accuracy: 0.9718 - val_loss: 0.3503 - val_categorical_accuracy: 0.9111\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0837 - categorical_accuracy: 0.9661 - val_loss: 0.2871 - val_categorical_accuracy: 0.9111\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0662 - categorical_accuracy: 0.9718 - val_loss: 0.2854 - val_categorical_accuracy: 0.8889\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0632 - categorical_accuracy: 0.9774 - val_loss: 0.2691 - val_categorical_accuracy: 0.8889\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0508 - categorical_accuracy: 0.9831 - val_loss: 0.2506 - val_categorical_accuracy: 0.8889\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0450 - categorical_accuracy: 0.9887 - val_loss: 0.2815 - val_categorical_accuracy: 0.8889\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0459 - categorical_accuracy: 0.9887 - val_loss: 0.2893 - val_categorical_accuracy: 0.9111\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0377 - categorical_accuracy: 0.9944 - val_loss: 0.2488 - val_categorical_accuracy: 0.9333\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0350 - categorical_accuracy: 0.9944 - val_loss: 0.3112 - val_categorical_accuracy: 0.8889\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0323 - categorical_accuracy: 0.9887 - val_loss: 0.3117 - val_categorical_accuracy: 0.8667\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0259 - categorical_accuracy: 0.9944 - val_loss: 0.2428 - val_categorical_accuracy: 0.8889\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0232 - categorical_accuracy: 0.9944 - val_loss: 0.2306 - val_categorical_accuracy: 0.9333\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0211 - categorical_accuracy: 0.9944 - val_loss: 0.2485 - val_categorical_accuracy: 0.9333\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0272 - categorical_accuracy: 0.9831 - val_loss: 0.2793 - val_categorical_accuracy: 0.9333\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0789 - categorical_accuracy: 0.9605 - val_loss: 0.1418 - val_categorical_accuracy: 0.9778\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1590 - categorical_accuracy: 0.9548 - val_loss: 0.1748 - val_categorical_accuracy: 0.9333\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1610 - categorical_accuracy: 0.9435 - val_loss: 0.3231 - val_categorical_accuracy: 0.8667\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1099 - categorical_accuracy: 0.9548 - val_loss: 0.4138 - val_categorical_accuracy: 0.8667\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2638 - categorical_accuracy: 0.9435 - val_loss: 0.3681 - val_categorical_accuracy: 0.8889\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1031 - categorical_accuracy: 0.9661 - val_loss: 0.2091 - val_categorical_accuracy: 0.9111\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1551 - categorical_accuracy: 0.9605 - val_loss: 0.2302 - val_categorical_accuracy: 0.9333\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0929 - categorical_accuracy: 0.9661 - val_loss: 0.2310 - val_categorical_accuracy: 0.9333\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0726 - categorical_accuracy: 0.9661 - val_loss: 0.2497 - val_categorical_accuracy: 0.9333\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0598 - categorical_accuracy: 0.9831 - val_loss: 0.2714 - val_categorical_accuracy: 0.9333\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0506 - categorical_accuracy: 0.9774 - val_loss: 0.2678 - val_categorical_accuracy: 0.9333\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0425 - categorical_accuracy: 0.9831 - val_loss: 0.2422 - val_categorical_accuracy: 0.9333\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0431 - categorical_accuracy: 0.9944 - val_loss: 0.2453 - val_categorical_accuracy: 0.9111\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0303 - categorical_accuracy: 0.9944 - val_loss: 0.2896 - val_categorical_accuracy: 0.9111\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0312 - categorical_accuracy: 0.9831 - val_loss: 0.2651 - val_categorical_accuracy: 0.9556\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0196 - categorical_accuracy: 1.0000 - val_loss: 0.2529 - val_categorical_accuracy: 0.9556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x204d8cd1e20>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, callbacks=[tb_callback], validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_19 (LSTM)              (None, 32)                6528      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6594 (25.76 KB)\n",
      "Trainable params: 6594 (25.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\faris\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('FINAL_LSTM_v1_12.5FPS_LSTM32UNIT.h5')\n",
    "# model.save('FCN_V2_10FPS.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\faris\\AppData\\Local\\Temp\\tmp8bo0igve\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\faris\\AppData\\Local\\Temp\\tmp8bo0igve\\assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import lite\n",
    "# Convert the model.\n",
    "converter = lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "converter.optimizations = [lite.Optimize.DEFAULT]\n",
    "converter.experimental_new_converter=True\n",
    "converter.target_spec.supported_ops = [lite.OpsSet.TFLITE_BUILTINS,\n",
    "lite.OpsSet.SELECT_TF_OPS]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoplifting\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "shoplifting\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "shoplifting\n",
      "normal\n",
      "normal\n",
      "shoplifting\n",
      "shoplifting\n",
      "shoplifting\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "shoplifting\n",
      "normal\n",
      "shoplifting\n",
      "normal\n",
      "shoplifting\n",
      "shoplifting\n",
      "shoplifting\n",
      "shoplifting\n",
      "normal\n",
      "shoplifting\n",
      "shoplifting\n",
      "shoplifting\n",
      "normal\n",
      "shoplifting\n",
      "normal\n",
      "shoplifting\n",
      "shoplifting\n",
      "shoplifting\n",
      "normal\n",
      "shoplifting\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(res)):\n",
    "    print(actions[np.argmax(res[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoplifting\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "shoplifting\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "shoplifting\n",
      "shoplifting\n",
      "shoplifting\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "normal\n",
      "shoplifting\n",
      "normal\n",
      "shoplifting\n",
      "normal\n",
      "shoplifting\n",
      "shoplifting\n",
      "shoplifting\n",
      "shoplifting\n",
      "normal\n",
      "shoplifting\n",
      "shoplifting\n",
      "shoplifting\n",
      "normal\n",
      "shoplifting\n",
      "normal\n",
      "shoplifting\n",
      "shoplifting\n",
      "shoplifting\n",
      "normal\n",
      "shoplifting\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(res)):\n",
    "    print(actions[np.argmax(y_test[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
